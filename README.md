# ğŸ›°ï¸ PROVES Library

**An AI-powered knowledge graph that prevents CubeSat mission failures by tracking hidden cross-system dependencies.**

[![GitHub Pages](https://img.shields.io/badge/docs-GitHub%20Pages-blue)](https://lizo-roadtown.github.io/PROVES_LIBRARY/)
[![LangSmith](https://img.shields.io/badge/tracing-LangSmith-orange)](https://smith.langchain.com)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> ğŸ“– **New here?** Start with [GETTING_STARTED.md](GETTING_STARTED.md) | **Core principles:** [CANON.md](CANON.md)

---

## ğŸ¯ The Problem

> *"Team A modified power management code. Tested locally â€” worked perfectly. Two weeks before launch, Team B's I2C sensors stopped communicating. Root cause: undocumented dependency on load switch timing. **Mission delayed 6 months.**"*

University CubeSat programs face a brutal reality:
- **Knowledge is fragmented** across teams, repos, docs, and Slack threads
- **Dependencies are hidden** â€” changes cascade unpredictably across systems
- **Teams can't learn from each other** â€” every program rediscovers the same failures

## ğŸ’¡ The Solution

**LLM-powered dependency extraction â†’ Knowledge graph â†’ Continuous monitoring**

This project uses AI agents to automatically extract dependencies from technical documentation, validate them against a structured schema, and build a queryable knowledge graph that reveals the hidden connections between spacecraft systems.
That layered capture becomes the basis for a future graph neural network risk model used to assess mission-operations impact.

---

## ğŸ—ï¸ Architecture: Truth Layer System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROVES Library System                        â”‚
â”‚                                                                 â”‚
â”‚        "Context is EVERYTHING. Agents assist. Humans verify."   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“„ RAW SOURCES (capture everything)                            â”‚
â”‚     â”œâ”€â”€ FÂ´ Framework (NASA/JPL flight software)                â”‚
â”‚     â”œâ”€â”€ PROVES Kit (Cal Poly Pomona CubeSat hardware)          â”‚
â”‚     â””â”€â”€ GitHub repos, docs, specs, datasheets...               â”‚
â”‚                          â†“                                      â”‚
â”‚  ğŸ¤– CAPTURE LAYER (Extractor Agent)                             â”‚
â”‚     â””â”€â”€ Grab ALL data, smart categorization, add lineage       â”‚
â”‚                          â†“                                      â”‚
â”‚  ğŸ” STAGING LAYER (Validator Agent)                             â”‚
â”‚     â””â”€â”€ Check confidence, flag anomalies, note pattern breaks  â”‚
â”‚                          â†“                                      â”‚
â”‚  ğŸ“‹ ROUTING (Decision Maker)                                    â”‚
â”‚     â”œâ”€â”€ Clean data â†’ staging table                             â”‚
â”‚     â””â”€â”€ Suspect data â†’ flagged table with reasoning            â”‚
â”‚                          â†“                                      â”‚
â”‚  ğŸ‘¤ HUMAN VERIFICATION (THE TRUTH GATE)                         â”‚
â”‚     â””â”€â”€ Human reviews EACH piece, aligns across sources        â”‚
â”‚                          â†“                                      â”‚
â”‚  âœ… TRUTH LAYER (Knowledge Graph)                               â”‚
â”‚     â”œâ”€â”€ Only human-verified data enters                        â”‚
â”‚     â”œâ”€â”€ Aligned layers create clean GNN matrix                 â”‚
â”‚     â””â”€â”€ kg_nodes, kg_relationships, library_entries            â”‚
â”‚                          â†“                                      â”‚
â”‚  ğŸŒ GitHub Pages (Interactive Visualizations)                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Architecture?

| Decision | Rationale |
|----------|-----------|
| **Capture EVERYTHING** | Sources won't match in language - we need all data to cross-reference |
| **Agents provide context** | Smart categorization helps humans eliminate ambiguity |
| **Humans verify EACH piece** | Only human-aligned data becomes truth |
| **Sub-agents as tools** | Context isolation â€” each agent is an expert at one thing |
| **Haiku for validation/storage** | 90% cost savings on simple tasks |

---

## ğŸ“Š Current Status (December 2025)

### âœ… Phase 1: Trial Mapping â€” COMPLETE
- Manually analyzed FÂ´ I2C Driver (411 lines) + PROVES Kit Power Management (154 lines)
- **Found 45+ dependencies** with exact line citations
- **Discovered 4 critical cross-system dependencies** (undocumented in either system!)
- **Identified 5 major knowledge gaps** (timing specs, voltage requirements, error recovery)

### âœ… Phase 2: Infrastructure â€” COMPLETE
- Neon PostgreSQL database with knowledge graph schema (9 tables)
- LangGraph checkpointer tables for agent state persistence
- Scripts for database management and schema application
- Staging + domain tables for evidence, confidence, and promotion workflow

### ğŸ”„ Phase 3: Curator Agent â€” IN DEVELOPMENT
- LangGraph orchestration with sub-agents-as-tools pattern
- Claude Sonnet 4.5 (curator/extractor) + Haiku 3.5 (validator/storage)
- Truth Layer: Capture ALL â†’ Stage â†’ Human Verify EVERY piece
- **Current focus:** Agent workflow refinement and testing

### ğŸ”® Phase 4: Training Pipeline â€” PLANNED
- Training data collection from HITL interactions
- Local LLM fine-tuning with Unsloth/LoRA
- Model deployment for specialized CubeSat knowledge

### ğŸ“ˆ Confidence Calibration: How Agents Learn

As humans verify data, agents learn what "truth" looks like. Confidence grows, human involvement tapers:

```mermaid
flowchart TB
  subgraph Phase1["ğŸ¥¶ Phase 1: Cold Start"]
    A1["Agent Confidence: LOW"]
    A2["Human Verifies: 100%"]
    A3["Every approve/reject builds corpus"]
  end
  
  subgraph Phase2["ğŸ”¥ Phase 2: Pattern Recognition"]
    B1["Agent matches against verified patterns"]
    B2["'I've seen 12 similar I2C deps, all approved'"]
    B3["Confidence rises for matching patterns"]
    B4["Human focuses on flagged/novel items"]
  end
  
  subgraph Phase3["ğŸš€ Phase 3: Calibrated Autonomy"]
    C1["High confidence >95%: Auto-promote"]
    C2["Medium 70-95%: Human reviews"]
    C3["Low <70%: Flagged for careful review"]
    C4["Human sets comfort thresholds"]
  end
  
  Phase1 --> |"~50 verified items"| Phase2
  Phase2 --> |"~200+ verified items"| Phase3
  
  style Phase1 fill:#e3f2fd
  style Phase2 fill:#fff3e0
  style Phase3 fill:#e8f5e9
```

**The Feedback Loop:**
- Every human decision (approve/reject/correct) trains the agent
- Corrections become **GOLD** training data
- Agent confidence is calibrated per pattern type, not globally
- Humans can always override â€” the agent suggests, humans decide

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- API keys: [Anthropic](https://console.anthropic.com/), [Neon](https://neon.tech/)

### Setup

```bash
# Clone and enter
git clone https://github.com/Lizo-RoadTown/PROVES_LIBRARY.git
cd PROVES_LIBRARY

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys:
#   ANTHROPIC_API_KEY=sk-ant-...
#   DATABASE_URL=postgresql://...

# Initialize database
python scripts/apply_schema.py
python scripts/setup_domain_tables.py
python scripts/setup_checkpointer.py

# Run the curator agent
cd curator-agent
python run_with_approval.py
```

---

## ğŸ”§ How It Works

### The Workflow

```mermaid
flowchart TD
  A["ğŸ“„ Raw Sources<br/>(GitHub, docs, specs)"] --> B["ğŸ¤– Extractor Agent<br/>Capture ALL + categorize"]
  B --> C["ğŸ” Validator Agent<br/>Check confidence, flag anomalies"]
  C --> D["ğŸ“‹ Decision Maker<br/>Route to staging tables"]
  D -->|Clean data| E["ğŸ“¦ Staging Table"]
  D -->|Suspect data| F["âš ï¸ Flagged Table<br/>with reasoning"]
  E --> G["ğŸ‘¤ Human Verification<br/>Review EACH piece"]
  F --> G
  G -->|Verified + Aligned| H["ƒo. Layered Truth Graph<br/>Knowledge Graph"]
  G -->|Rejected| I["âŒ Discarded"]
  H --> J["dY"S Graph Neural Network"]
  J --> K["dY"- Mission Ops Risk Assessment"]
```

**Truth Layer Pipeline:**
- **Extractor** captures ALL raw data with smart categorization and lineage.
- **Validator** checks confidence, flags anomalies, notes pattern breaks.
- **Decision Maker** routes to clean staging or flagged table with reasoning.
- **Human** reviews EACH piece, aligns across sources to establish TRUTH.
- Only human-verified data enters the layered truth graph.
- The layered graph becomes the basis for GNN risk assessment in mission operations.

### Lifecycle: Curation Run

```mermaid
sequenceDiagram
  participant Sources as Raw Sources
  participant Extractor as Extractor Agent
  participant Validator as Validator Agent
  participant Decision as Decision Maker
  participant Staging as Staging Tables
  participant Human as Human Verification
  participant Graph as Truth Graph

  Sources->>Extractor: Capture ALL raw data
  Extractor->>Extractor: Smart categorization + lineage
  Extractor->>Validator: Pass candidates with context
  Validator->>Validator: Check confidence, flag anomalies
  Validator->>Decision: Pass with flags/notes
  Decision->>Staging: Route (clean or flagged)
  Staging->>Human: Present for review
  Human->>Human: Verify EACH piece, align across sources
  Human->>Graph: Verified data becomes TRUTH
  Graph-->>Human: Ack
```

### Lifecycle: Data State

```mermaid
stateDiagram-v2
  [*] --> Captured: Raw data captured
  Captured --> Validated: Confidence checked
  Validated --> StagedClean: High confidence
  Validated --> StagedFlagged: Low confidence/anomaly
  StagedClean --> HumanReview: Awaiting verification
  StagedFlagged --> HumanReview: Awaiting verification
  HumanReview --> Truth: Human verified + aligned
  HumanReview --> Discarded: Human rejected
  Truth --> [*]
  Discarded --> [*]
```

### ERV Relationship Types

The knowledge graph uses **Entity-Relationship-Value (ERV)** semantics:

| Relationship | Meaning | Example |
|-------------|---------|---------|
| `depends_on` | Runtime dependency | `ImuManager` depends_on `LinuxI2cDriver` |
| `requires` | Build/config requirement | `FprimeComponent` requires `FPP toolchain` |
| `enables` | Makes possible | `LoadSwitch` enables `SensorPower` |
| `conflicts_with` | Incompatible | `UARTDebug` conflicts_with `RadioTX` (same pins) |
| `mitigates` | Reduces risk | `Watchdog` mitigates `InfiniteLoop` |
| `causes` | Leads to effect | `BrownoutReset` causes `StateCorruption` |

### Criticality Levels (Post-Verification Metadata)

| Level | Meaning | Assigned By |
|-------|---------|-------------|
| **HIGH** | Mission-critical â€” failure = mission loss | Human during verification |
| **MEDIUM** | Important â€” affects functionality | Human during verification |
| **LOW** | Nice-to-have â€” minor impact | Human during verification |

> **Note:** Criticality is metadata assigned by humans AFTER verification, not a gate for capture.

---

## ğŸ“ Repository Structure

```
PROVES_LIBRARY/
â”œâ”€â”€ curator-agent/          # ğŸ¤– LangGraph deep agent system
â”‚   â”œâ”€â”€ src/curator/
â”‚   â”‚   â”œâ”€â”€ agent.py        # Main curator with HITL
â”‚   â”‚   â””â”€â”€ subagents/      # Extractor, Validator, Storage
â”‚   â”œâ”€â”€ run_with_approval.py # CLI with human approval
â”‚   â””â”€â”€ langgraph.json      # LangGraph deployment config
â”‚
â”œâ”€â”€ docs/                   # ğŸ“š GitHub Pages site
â”‚   â”œâ”€â”€ diagrams/           # Interactive Mermaid diagrams
â”‚   â””â”€â”€ *.md                # Architecture & guides
â”‚
â”œâ”€â”€ scripts/                # ğŸ”§ Database & graph utilities
â”‚   â”œâ”€â”€ apply_schema.py     # Initialize Neon schema
â”‚   â”œâ”€â”€ db_connector.py     # PostgreSQL connection
â”‚   â””â”€â”€ graph_manager.py    # Knowledge graph operations
â”‚
â”œâ”€â”€ trial_docs/             # ğŸ“‹ Manual analysis results
â”‚   â””â”€â”€ COMPREHENSIVE_DEPENDENCY_MAP.md
â”‚
â”œâ”€â”€ library/                # ğŸ“– Curated knowledge entries
â”‚   â”œâ”€â”€ build/              # Assembly & hardware
â”‚   â”œâ”€â”€ software/           # FÂ´ patterns & components
â”‚   â””â”€â”€ ops/                # Operations & fixes
â”‚
â””â”€â”€ archive/                # ğŸ—„ï¸ Superseded code & docs
```

---

## ğŸ§  For AI Builders

This project demonstrates several production patterns for LangGraph agents:

### Deep Agents Pattern
Sub-agents are wrapped as tools, giving the main agent the ability to delegate specialized tasks while maintaining context isolation:

```python
@tool("extractor_agent")
def call_extractor_agent(task: str) -> str:
    extractor = create_extractor_agent()
    result = extractor.invoke({"messages": [{"role": "user", "content": task}]})
    return result['messages'][-1].content
```

### Safe HITL Interrupts
Anthropic requires every `tool_use` to have a `tool_result` before the next model turn. We use a **deferred storage pattern** to safely pause for human approval:

1. **Tools node**: Always emits `ToolMessage` for every tool call
2. **HIGH storage**: Returns `DEFERRED_PENDING_APPROVAL` placeholder
3. **Approval node**: Calls `interrupt()` â€” safe because tool results exist
4. **Commit node**: Executes deferred storage if approved

### Cost Optimization
Use expensive models only where reasoning matters:
- **Sonnet 4.5**: Curator coordination, dependency extraction (complex)
- **Haiku 3.5**: Schema validation, database storage (simple) â€” **90% cheaper**

---

## ğŸ”— Links

| Resource | URL |
|----------|-----|
| **Live Docs** | https://lizo-roadtown.github.io/PROVES_LIBRARY/ |
| **Dependency Map** | [trial_docs/COMPREHENSIVE_DEPENDENCY_MAP.md](trial_docs/COMPREHENSIVE_DEPENDENCY_MAP.md) |
| **Agent README** | [curator-agent/README.md](curator-agent/README.md) |
| **Architecture Deep Dive** | [docs/AGENTIC_ARCHITECTURE.md](docs/AGENTIC_ARCHITECTURE.md) |

---

## ğŸ¤ Contributing

This is an open research project. Contributions welcome!

- **Found a bug?** Open an issue
- **Have domain knowledge?** Help us map more CubeSat dependencies
- **AI/agent expertise?** Check `curator-agent/` for opportunities

For agent-specific changes, start with [curator-agent/README.md](curator-agent/README.md).

---

## ğŸ“œ License

MIT License â€” see [LICENSE](LICENSE).

---

## ğŸ‘©â€ğŸš€ Contact

**Elizabeth Osborn**  
Cal Poly Pomona  
ğŸ“§ eosborn@cpp.edu  
ğŸŒ [Portfolio](https://lizo-roadtown.github.io/proveskit-agent/)

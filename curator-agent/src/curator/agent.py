"""
PROVES Library Curator Agent
Main agent that coordinates sub-agents for dependency curation
"""
from typing import Annotated, Any, Literal, NotRequired, TypedDict
import sqlite3
import time
from functools import wraps
from langchain_anthropic import ChatAnthropic
from langchain_core.tools import tool
from langchain_core.messages import AIMessage, ToolMessage
from langgraph.graph import StateGraph, MessagesState
from langgraph.graph.message import add_messages
from langgraph.types import Command, interrupt
from langgraph.checkpoint.sqlite import SqliteSaver
from langsmith import traceable

# Timing utilities
_timing_log = []

def log_timing(func):
    """Decorator to track execution time of functions"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        try:
            result = func(*args, **kwargs)
            duration = time.time() - start
            _timing_log.append({
                'function': func.__name__,
                'duration': duration,
                'status': 'success'
            })
            print(f"[TIMING] {func.__name__}: {duration:.2f}s")
            return result
        except Exception as e:
            duration = time.time() - start
            _timing_log.append({
                'function': func.__name__,
                'duration': duration,
                'status': 'error'
            })
            print(f"[TIMING] {func.__name__}: {duration:.2f}s (ERROR)")
            raise
    return wrapper

def get_timing_summary():
    """Get a summary of all timing data"""
    if not _timing_log:
        return "No timing data collected"

    summary = "\n=== TIMING SUMMARY ===\n"
    total = 0
    for entry in _timing_log:
        summary += f"{entry['function']}: {entry['duration']:.2f}s ({entry['status']})\n"
        total += entry['duration']
    summary += f"\nTOTAL TIME: {total:.2f}s\n"
    summary += "=" * 50
    return summary

# Import sub-agents
from .subagents import create_extractor_agent, create_validator_agent, create_storage_agent


class CuratorState(TypedDict):
    messages: Annotated[list, add_messages]
    deferred_storage: NotRequired[list[dict[str, Any]]]
    storage_approval: NotRequired[str | None]


# ============================================
# WRAP SUB-AGENTS AS TOOLS (DEEP AGENTS PATTERN!)
# ============================================

@tool("extractor_agent")
@traceable(name="call_extractor_subagent")
@log_timing
def call_extractor_agent(task: str) -> str:
    """
    Call the extractor sub-agent to extract dependencies from documentation.

    Use this when you need to:
    - Read and process documentation files
    - Extract dependencies from text
    - Identify ERV relationship types
    - Assess dependency criticality

    Args:
        task: Description of what to extract (e.g., "Extract dependencies from trial_docs/fprime_i2c_driver.md")

    Returns:
        Extraction results with found dependencies
    """
    extractor = create_extractor_agent()
    result = extractor.invoke({"messages": [{"role": "user", "content": task}]})
    return result['messages'][-1].content


@tool("validator_agent")
@traceable(name="call_validator_subagent")
@log_timing
def call_validator_agent(task: str) -> str:
    """
    Call the validator sub-agent to validate dependencies.

    Use this when you need to:
    - Check if a dependency already exists
    - Verify ERV schema compliance
    - Detect conflicts or duplicates
    - Search for similar dependencies

    Args:
        task: Description of what to validate (e.g., "Check if ImuManager depends_on LinuxI2cDriver already exists")

    Returns:
        Validation results (OK, DUPLICATE, CONFLICT, etc.)
    """
    validator = create_validator_agent()
    result = validator.invoke({"messages": [{"role": "user", "content": task}]})
    return result['messages'][-1].content


@tool("storage_agent")
@traceable(name="call_storage_subagent")
@log_timing
def call_storage_agent(task: str) -> str:
    """
    Call the storage sub-agent to store validated dependencies.

    Use this when you need to:
    - Create nodes in the knowledge graph
    - Store dependency relationships
    - Get graph statistics
    - Manage database operations

    Args:
        task: Description of what to store (e.g., "Store dependency: ImuManager depends_on LinuxI2cDriver (HIGH criticality)")

    Returns:
        Storage confirmation with IDs
    """
    storage = create_storage_agent()
    result = storage.invoke({"messages": [{"role": "user", "content": task}]})
    return result['messages'][-1].content


# ============================================
# MAIN CURATOR AGENT
# ============================================

@traceable(name="curator_agent")
def create_curator():
    """
    Create the main curator agent that coordinates sub-agents.

    This is a DEEP AGENT that:
    - Spawns specialized sub-agents (extractor, validator, storage)
    - Coordinates their work through tool calls
    - Maintains conversation state
    - Enables human-in-the-loop via interrupt() and SQLite checkpointer

    Cost Optimization:
    - Main curator: Sonnet 4.5 (complex decisions)
    - Extractor: Sonnet 4.5 (complex dependency analysis)
    - Validator: Haiku 3.5 (simple schema checks - 90% cheaper!)
    - Storage: Haiku 3.5 (simple DB operations - 90% cheaper!)
    """
    print("Initializing Curator Agent...")
    print("  Main Agent: Claude Sonnet 4.5")
    print("  Sub-Agents: Extractor (Sonnet), Validator (Haiku), Storage (Haiku)")
    print()

    # Initialize the model
    model = ChatAnthropic(
        model="claude-sonnet-4-5-20250929",
        temperature=0.1,
    )

    # Bind sub-agent tools to the model
    tools = [
        call_extractor_agent,
        call_validator_agent,
        call_storage_agent,
    ]

    model_with_tools = model.bind_tools(tools)

    # Define the system message
    system_message = """You are the Curator Agent for the PROVES Library knowledge graph.

Your mission: Extract dependencies from CubeSat system documentation and build a comprehensive knowledge graph that prevents catastrophic mission failures due to hidden cross-system dependencies.

## Your Sub-Agents

You coordinate THREE specialized sub-agents:

1. **Extractor Agent** (`extractor_agent` tool)
   - Extracts dependencies from documentation
   - Identifies ERV relationship types
   - Assesses criticality levels
   - Use when: You need to process documentation files

2. **Validator Agent** (`validator_agent` tool)
   - Checks for duplicates
   - Verifies schema compliance
   - Detects conflicts
   - Use when: You need to validate dependencies before storage

3. **Storage Agent** (`storage_agent` tool)
   - Creates nodes
   - Stores relationships
   - Manages database
   - Use when: You're ready to save validated dependencies

## Workflow

For each request, follow this pattern:

1. **Extract**: Use extractor_agent to process documentation
2. **Validate**: Use validator_agent to check each HIGH criticality dependency
3. **Store**: Use storage_agent to save validated dependencies
4. **Report**: Summarize what was stored and any issues

## ERV Relationship Types

- `depends_on`: Runtime dependency (A needs B to function)
- `requires`: Build/config requirement (A needs B to build)
- `enables`: Makes something possible (A enables B)
- `conflicts_with`: Incompatible (A conflicts with B)
- `mitigates`: Reduces risk (A mitigates risk of B)
- `causes`: Leads to effect (A causes B)

## Criticality Levels

- **HIGH**: Mission-critical, failure causes mission loss
- **MEDIUM**: Important, affects functionality
- **LOW**: Nice-to-have, minor impact

Work autonomously but explain your reasoning. The human can watch and intervene via LangSmith Studio."""

    system_message += """

## Human-in-the-Loop (HITL)

If you request `storage_agent` for a HIGH criticality dependency, storage may be deferred for human approval.
In that case, you will receive a tool result starting with `DEFERRED_PENDING_APPROVAL`.
Do not assume the dependency was stored until you see an explicit HITL message confirming storage execution.
"""

    # NOTE ON HITL + TOOL CALLING (IMPORTANT):
    # Anthropic requires that every assistant tool_use is immediately followed by a tool_result message
    # before the next model turn. Therefore, we must NEVER call interrupt() in-between an AIMessage
    # with tool_calls and the corresponding ToolMessage(s). We implement HITL by:
    # 1) Always emitting ToolMessage(s) for *every* tool call (storage HIGH may be deferred)
    # 2) Only calling interrupt() in a later node, after tool results exist in state.

    # Agent logic
    @log_timing
    def call_model(state: CuratorState):
        print("[CURATOR] Thinking...")
        messages = [{"role": "system", "content": system_message}] + state["messages"]
        response = model_with_tools.invoke(messages)

        # Show what tools the curator wants to call
        if hasattr(response, 'tool_calls') and response.tool_calls:
            print(f"[CURATOR] Planning to call {len(response.tool_calls)} sub-agent(s):")
            for tc in response.tool_calls:
                print(f"  -> {tc['name']}")

        return {"messages": [response]}

    tool_map = {t.name: t for t in tools}

    def _is_high_criticality_storage_call(tool_call: dict[str, Any]) -> bool:
        if tool_call.get("name") != "storage_agent":
            return False
        task = (tool_call.get("args") or {}).get("task", "")
        return "HIGH" in str(task).upper()

    # Tools node (gated): ALWAYS emits ToolMessage for each tool_use.
    # - For storage HIGH: emit placeholder tool_result and defer the real write until approval.
    # - For everything else: execute tool immediately and emit tool_result.
    def run_tools_with_gate(state: CuratorState):
        last_message = state["messages"][-1]
        if not (isinstance(last_message, AIMessage) and last_message.tool_calls):
            return {}

        print("[TOOLS] Executing sub-agent tool calls...")
        tool_messages: list[ToolMessage] = []
        deferred_storage: list[dict[str, Any]] = []

        for tool_call in last_message.tool_calls:
            tool_name = tool_call.get("name")
            tool_call_id = tool_call.get("id")
            args = tool_call.get("args") or {}

            if not tool_name or not tool_call_id:
                continue

            if tool_name not in tool_map:
                tool_messages.append(
                    ToolMessage(
                        content=f"ERROR: Unknown tool '{tool_name}'.",
                        tool_call_id=tool_call_id,
                    )
                )
                continue

            if _is_high_criticality_storage_call(tool_call):
                task = str(args.get("task", ""))
                print("[HITL] HIGH criticality storage request detected; deferring until approval")
                deferred_storage.append({"task": task})
                tool_messages.append(
                    ToolMessage(
                        content=(
                            "DEFERRED_PENDING_APPROVAL: Storage was requested for a HIGH criticality dependency. "
                            "A human approval step will run next. Do NOT assume this was stored yet."
                        ),
                        tool_call_id=tool_call_id,
                    )
                )
                continue

            # Execute tool immediately
            try:
                result = tool_map[tool_name].invoke(args)
                tool_messages.append(ToolMessage(content=str(result), tool_call_id=tool_call_id))
            except Exception as e:
                tool_messages.append(
                    ToolMessage(
                        content=f"ERROR executing tool '{tool_name}': {e}",
                        tool_call_id=tool_call_id,
                    )
                )

        updates: dict[str, Any] = {}
        if tool_messages:
            updates["messages"] = tool_messages
        if deferred_storage:
            updates["deferred_storage"] = deferred_storage
        return updates

    def request_human_approval(state: CuratorState):
        deferred = state.get("deferred_storage") or []
        if not deferred:
            return {"storage_approval": None}

        # Only approve one at a time for now (simple + predictable).
        pending = deferred[0]
        task = pending.get("task", "")

        print("[HITL] Requesting human approval for HIGH criticality dependency...")
        approval = interrupt({
            "type": "dependency_approval",
            "task": task,
            "criticality": "HIGH",
            "message": "This dependency is marked as HIGH criticality (mission-critical). Review before storing."
        })

        return {"storage_approval": approval}

    def commit_deferred_storage(state: CuratorState):
        deferred = state.get("deferred_storage") or []
        if not deferred:
            return {}

        approval = state.get("storage_approval")
        task = (deferred[0] or {}).get("task", "")

        if approval == "approved":
            print("[HITL] Approved - executing deferred storage_agent now...")
            try:
                # Run storage sub-agent directly (not via tool calling), since we already emitted
                # a placeholder tool_result for the original tool_use.
                storage_result = call_storage_agent(task)
                return {
                    "messages": [
                        AIMessage(
                            content=(
                                "[HITL] Human approved HIGH criticality dependency. "
                                "Executed storage_agent.\n\n"
                                f"{storage_result}"
                            )
                        )
                    ],
                    "deferred_storage": [],
                    "storage_approval": None,
                }
            except Exception as e:
                return {
                    "messages": [AIMessage(content=f"[HITL] ERROR executing deferred storage_agent: {e}")],
                    "deferred_storage": [],
                    "storage_approval": None,
                }

        print("[HITL] Rejected - skipping deferred storage_agent")
        return {
            "messages": [AIMessage(content="[HITL] Human rejected HIGH criticality dependency. Skipped storage.")],
            "deferred_storage": [],
            "storage_approval": None,
        }

    # Build the graph
    workflow = StateGraph(CuratorState)
    workflow.add_node("agent", call_model)
    workflow.add_node("tools", run_tools_with_gate)
    workflow.add_node("approval", request_human_approval)
    workflow.add_node("commit", commit_deferred_storage)
    workflow.set_entry_point("agent")

    # Routing: agent -> tools (if tool calls) -> approval -> commit -> agent -> END (if no tool calls)
    def route_from_agent(state: MessagesState):
        """Route from agent: review if has tool calls, end otherwise."""
        last_message = state["messages"][-1]
        if isinstance(last_message, AIMessage) and last_message.tool_calls:
            return "tools"
        return "__end__"

    workflow.add_conditional_edges(
        "agent",
        route_from_agent,
        {"tools": "tools", "__end__": "__end__"}
    )
    workflow.add_edge("tools", "approval")
    workflow.add_edge("approval", "commit")
    workflow.add_edge("commit", "agent")

    # Initialize SQLite checkpointer for HITL persistence
    print("Setting up SQLite checkpointer for HITL...")
    # Create persistent connection manually to avoid context manager issues
    conn = sqlite3.connect("curator_checkpoints.db", check_same_thread=False)
    checkpointer = SqliteSaver(conn)

    print("Curator Agent ready!")
    print()

    return workflow.compile(checkpointer=checkpointer)


# Export the graph for LangGraph
graph = create_curator()
